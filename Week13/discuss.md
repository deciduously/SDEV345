A hash table is an incredibly useful tool.  The trees we've been looking at in this course so far are great for storing sorted data for efficient lookup, but there are still issues.  WHen using a plain Binary Search tree, we saw that the order in which the data is inserted makes a huge difference - in the worst case, your BST can end up with the same performance characteristics as a linked list (i.e. dismal).  We can address that problem using a self-balancing structure such as a Red-Black tree, which adjusts on each write operation to maintain O(log(n)) layers.  This helps, but you pay for it dearly - the code we wrote to rebalance the tree is significantly more complex than the code to insert for an unbalanced tree.

A hash table solves a lot of these problems - you provide a function that hashes each value to be stored.  Then, a lookup is reduced to simply computing this hash.  You can then hop directly to the destination - an operation which takes constant time instead of being a function of the size of the set.

It sounds like a silver bullet, but of course, the phrase "just provide a hash function" belies considerable complexity.  A hash table works best when your hash function does not produce collisions, but in practice this is difficult.  If you know every single key ahead of time, you may be able to select and use a "perfect" has function, or one that does not produce collisions.  You can further constrain that to a "minimal perfect" function which is also guaranteed to be as space-efficient as possible, and uses all locales while still avoiding any collisions.

In practice, we rarely know all keys ahead of time, so must select an imperfect hash function with as uniform a distribution of keys as possible.  In this case, you must expect some hash collisions, which means that it is not quite sufficient to simply compute the hash for a lookup as your result may correspond to multiple keys.  One common strategy is called "separate chaining", which actually places a linked list at each hash "bucket".  Then, after computing the hash, your program will need to traverse this list as well to find your value, which does increase the runtime of the overall lookup.  Ideally, you've selected a hash function which results in short lists.  In most cases, these lists should be 0-1 elements long to cut down on list operations, but in the case of a collision may inflate to two or three members.  If they're getting long than that, you have a bad hash function.

Some structures may use a strategy called "2-choice hashing", which uses two separate hash functions on each key.  It then selects the list which has fewer objects already.  This will lead to shorter lists, but does inflate the logic and runtime required.

Hash tables will need to be rehashed as they grow.  At some point, you no longer have enough buckets to hold on to all your entries without the corresponding linked lists growing such that your constant-time operations are no longer constant.  In this case, an entirely new, larger table will be allocated and each key will be re-hashed and moved within this larger structure.  This increases the number of buckets, or your space complexity, but reduces the size of each list, or the time complexity, and will allow the table to continue to grow.

Hash tables generally are very fast and are widely used.  Many languages like Python include them as a core data type.  However, not all problems are well suited.  For instance, a hash table means your data will be spread all throughout memory, and adjacent keys may not actually ned up adjacent in RAM.  A liner, compact structure may be able to use your processor's cache to traverse very efficiently, whereas in a hash table this jumping around may slow that down considerably.  More generally, after hashing a key you only have information about that specific key.  If you needed to then get information about other similar keys, you can't - their hashes may (and probably will) be entirely unrelated.

Like with anything, you must fit the structure to the task.

Works cited:

Lemire, Daniel. “Do Hash Tables Work in Constant Time?” Daniel Lemire's Blog, 24 Nov. 2015, lemire.me/blog/2009/08/18/do-hash-tables-work-in-constant-time/.